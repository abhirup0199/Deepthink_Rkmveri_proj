{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"aw9iL-wPGCZG"},"outputs":[{"ename":"ValueError","evalue":"No objects to concatenate","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-6-9409b834cd90\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 67\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# Combine all predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 67\u001b[0;31m \u001b[0mpredictions_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# Evaluate using MAPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 382\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 445\u001b[0;31m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean_keys_and_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;31m# figure out what our result ndim is going to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m_clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 507\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: No objects to concatenate"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_absolute_error\n","\n","# Load the dataset\n","file_path = '/content/Data.xlsx'  # Replace with your file path\n","df = pd.read_excel(file_path)\n","\n","# Reshape data from wide to long format\n","df_long = df.melt(id_vars=[\"Warehouse id\", \"Region\", \"SKU id\"],\n","                  var_name=\"Date\",\n","                  value_name=\"Sales\")\n","\n","# Convert the 'Date' column to datetime format\n","df_long['Date'] = pd.to_datetime(df_long['Date'])\n","\n","# Sort the data for time series processing\n","df_long = df_long.sort_values(by=[\"Warehouse id\", \"SKU id\", \"Date\"])\n","\n","# Fill missing values (if any) with 0\n","df_long['Sales'] = df_long['Sales'].fillna(0)\n","\n","# Feature Engineering: Add lag and rolling mean features\n","def create_features(data, lags, rolling_windows):\n","    for lag in lags:\n","        data[f'lag_{lag}'] = data.groupby(['Warehouse id', 'SKU id'])['Sales'].shift(lag)\n","    for window in rolling_windows:\n","        data[f'rolling_mean_{window}'] = data.groupby(['Warehouse id', 'SKU id'])['Sales'].shift(1).rolling(window).mean()\n","    return data\n","\n","df_long = create_features(df_long, lags=[1, 2, 3], rolling_windows=[2, 3])\n","\n","# Drop rows with NaN values (caused by lag/rolling features)\n","df_long = df_long.dropna()\n","\n","# Split data into training and testing sets\n","train = df_long[df_long['Date'] \u003c '2021-06-01']\n","test = df_long[df_long['Date'] == '2021-06-01']\n","\n","# Define features and target variable\n","features = [col for col in df_long.columns if col.startswith('lag_') or col.startswith('rolling_mean_')]\n","target = 'Sales'\n","\n","# Train a separate model for each SKU-Warehouse combination\n","predictions = []\n","for (warehouse, sku), group in train.groupby(['Warehouse id', 'SKU id']):\n","    # Train-test split\n","    X_train = group[features]\n","    y_train = group[target]\n","\n","    # Test data for this SKU-Warehouse\n","    test_group = test[(test['Warehouse id'] == warehouse) \u0026 (test['SKU id'] == sku)]\n","    X_test = test_group[features]\n","\n","    # Train the model\n","    model = RandomForestRegressor(random_state=42)\n","    model.fit(X_train, y_train)\n","\n","    # Predict for June 2021\n","    if not X_test.empty:\n","        test_group['Forecasted Sales'] = model.predict(X_test)\n","        predictions.append(test_group)\n","\n","# Combine all predictions\n","predictions_df = pd.concat(predictions)\n","\n","# Evaluate using MAPE\n","def calculate_mape(actual, forecasted):\n","    mape = np.mean(np.abs((actual - forecasted) / actual)) * 100\n","    return mape\n","\n","mape = calculate_mape(predictions_df['Sales'], predictions_df['Forecasted Sales'])\n","\n","# Save predictions to a file\n","predictions_df.to_csv('June_2021_Forecast.csv', index=False)\n","\n","# Output MAPE\n","print(f\"MAPE: {mape:.2f}%\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN+Ityovj8G1z4NO6pdSHxv","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}